{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weather.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmsCqGi4mq+DF3VATMEWKg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1C_K9DU1flE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcQP-ONpznDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.layers import Input, Conv2D, Add, BatchNormalization, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZUxHa0CTFZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train = np.load('/gdrive/My Drive/data_dacon/data/x_train.npy')\n",
        "y_train = np.load('/gdrive/My Drive/data_dacon/data/y_train.npy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu0batBpgZY9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iGdky1C1KUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def mae(y_true, y_pred) :\n",
        "    \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    \n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    \n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    \n",
        "    over_threshold = y_true >= 0.1\n",
        "    \n",
        "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    \n",
        "    y_true = y_true.reshape(1, -1)[0]\n",
        "    \n",
        "    y_pred = y_pred.reshape(1, -1)[0]\n",
        "    \n",
        "    remove_NAs = y_true >= 0\n",
        "    \n",
        "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
        "    \n",
        "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
        "    \n",
        "    return(f1_score(y_true, y_pred))\n",
        "\n",
        "def maeOverFscore(y_true, y_pred):\n",
        "    \n",
        "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)\n",
        "\n",
        "def fscore_keras(y_true, y_pred):\n",
        "    score = tf.py_function(func=fscore, inp=[y_true, y_pred], Tout=tf.float32, name='fscore_keras')\n",
        "    return score\n",
        "\n",
        "def score(y_true, y_pred):\n",
        "    score = tf.py_function(func=maeOverFscore, inp=[y_true, y_pred], Tout=tf.float32,  name='custom_mse') \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEGz0ceB07hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  inputs = Input(x_train.shape[1:])\n",
        "  bn=BatchNormalization()(inputs)\n",
        "  conv0=Conv2D(32, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
        "  \n",
        "  bn=BatchNormalization()(conv0)\n",
        "  conv=Conv2D(16, kernel_size=2, strides=1, padding='same', activation='relu')(bn)\n",
        "  conc =concatenate([conv0, conv], axis=3)\n",
        "\n",
        "  bn=BatchNormalization()(conc)\n",
        "  \n",
        "  outputs = Conv2D(1, kernel_size=1, strides=1, padding='same', activation='relu')(bn)\n",
        "\n",
        "  model = Model(inputs,outputs)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNjjaVAP1H4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(x_data, y_data, k,test):\n",
        "    \n",
        "    k_fold = KFold(n_splits=k, shuffle=True, random_state=7676)\n",
        "    \n",
        "    predicts = []\n",
        "  \n",
        "    for train_idx, val_idx in k_fold.split(x_data):\n",
        "        x_train, y_train = x_data[train_idx], y_data[train_idx]\n",
        "        x_val, y_val = x_data[val_idx], y_data[val_idx]\n",
        "        \n",
        "        model = build_model()\n",
        "        model.compile(loss='mae', optimizer='adam', metrics=[score, fscore_keras])\n",
        "        model.fit(x_train, y_train, epochs=50, batch_size=128, validation_data=(x_val, y_val))\n",
        "        predicts.append(model.predict(test))\n",
        "        \n",
        "    return predicts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8POQfYw9BH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv('/gdrive/My Drive/data_dacon/data/sample_submission.csv')\n",
        "test = np.load('/gdrive/My Drive/data_dacon/data/newtest.npy')\n",
        "test = test[:,:,:,:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZQCMxPE1OWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicts = train_model(x_train, y_train, 5,test)\n",
        "\n",
        "predict = sum(predicts)/len(predicts)\n",
        "\n",
        "submission.iloc[:,1:] = predict.reshape(-1,1600)\n",
        "submission.to_csv('/gdrive/My Drive/data_dacon/data/submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}